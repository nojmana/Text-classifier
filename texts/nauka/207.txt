
Notowania:
więcej notowań »
Ostatnia aktualizacja:             Dziś
        14:54

Waluty:
zobacz więcej »
Ostatnia aktualizacja:             Dziś
        14:54

Surowce:
zobacz więcej »
Ostatnia aktualizacja:             Dziś
        14:54
Ma na imię Norman i lepiej, by nie wymknął się spod kontroli badaczy. Naukowcy z Massachusetts Institute of Technology stworzyli psychopatyczną sztuczną inteligencję. Badacze z jednej z najlepszych uczelni technicznych na świecie od początku planowali stworzyć e-psychopatę. Tak kierowali rozwojem Normana, by nabył i wykazywał jak najwięcej negatywnych cech.









Maszyny czytają ze zrozumieniem. W testach pokonały ludzi



Oparte na głębokich sieciach neuronowych sztuczne inteligencje opracowane niezal... zobacz więcej »



Oparte na głębokich sieciach neuronowych sztuczne inteligencje opracowane niezal... zobacz więcej »Jak podaje CNN, w tym celu pokazywali Normanowi obrazki i grafiki z "najciemniejszych zakątków serwisu Reddit", który agreguje treści wstawiane przez internautów.Następnie sprawdzali reakcje Normana w teście Rorschacha, czyli popularnym teście plam polegającym - w dużym uproszczeniu - na rozpoznawaniu kształtów z prezentowanych plansz. Ten sam test rozwiązywała też standardowa sztuczna inteligencja. Co się okazało? Tam, gdzie standardowy algorytm widział czerwono-biały parasol, Norman dostrzegał człowieka poddawanego wstrząsom elektrycznym. Inny przykład? Standardowa sztuczna inteligencja widzi kwiaty i ciasta weselne, a Norman zastrzelonego mężczyznę i człowieka zabitego przez pędzący samochód. Naukowcy z MIT, którzy stworzyli Normana, oświadczyli, że widzi on śmierć lub cierpienie niemal na każdej zaprezentowanej planszy. Ich zdaniem to efekt ciągłej ekspozycji na treści z "ciemnej" strony internetu. Badacze podkreślają, że przykład Normana jest ważny dla twórców sztucznej inteligencji, bo pokazuje, że jej zachowanie jest w dużej mierze zdeterminowane informacjami, które zdobywa podczas nauki.Podobne wnioski można było wyciągnąć już wcześniej po tym, jak Microsoft stworzył czatbota o nazwie Tay, który uczył się od internautów. W zaledwie 24 godziny zmienił się z niewinnej nastolatki w zepsutą rasistkę i fankę Adolfa Hitlera. Po tym incydencie technologiczny gigant postanowił wyłączyć Tay.Autor: msz//bgr                    /                    Źródło: CNN  Publikowane komentarze są prywatnymi opiniami użytkowników portalu. TVN24BiŚ nie ponosi odpowiedzialności za treść opinii.Copyright (C) 1997-2018 Korzystanie z materiałów redakcyjnych TVN S.A. / TVN Media Sp. z o.o. wymaga wcześniejszej zgody TVN S.A./ TVN Media Sp. z o.o. oraz zawarcia stosownej umowy licencyjnej. Na podstawie art. 25 ust. 1 pkt. 1 b) ustawy o prawie autorskim i prawach pokrewnych TVN S.A. / TVN Media Sp. z o.o. wyraźnie zastrzega, że dalsze rozpowszechnianie artykułów zamieszczonych w programach oraz na stronach internetowych TVN S.A. / TVN Media Sp. z o.o. jest zabronione